## 20201103

[TOC]

CUDA需要了解下。CuDNN是什么？ TensorRT是什么？NGC



### CUDA编程

CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.

在没有cuda之前，gpu一般只是用来进行图形渲染。现在开发人员可以通过调用CUDA的API，来进行并行编程，达到高性能计算目的。

**高性能计算HPC**

CUDA 11 现已推出



我们将cpu以及系统的内存称为主机，而将GPU以及其内存称为设备。

在GPU设备上执行的函数通常称为核函数（Kernel）

``` c
#include <iostream>

__global__ void kernel(void) {
    
}

int main(void) {
    kernel<<<1, 1>>> ();
    printf("Hello, World!\n");
    return 0;
}
```

对kernel函数的定义，并且带有修饰符__global__

对这个空函数的调用，并且带有修饰符<<<1, 1>>>



### cuDNN

The NVIDIA CUDA® Deep Neural Network library (cuDNN) is a GPU-accelerated library of primitives for [deep neural networks](https://developer.nvidia.com/deep-learning).

NVIDIA cuDNN是用于深度神经网络的GPU加速库



### TensorRT

NVIDIA TensorRT™ 是用于高性能深度学习推理的 SDK。此 SDK 包含深度学习推理优化器和运行时环境，可为深度学习推理应用提.

在推理过程中，基于 TensorRT 的应用程序的执行速度可比 CPU 平台的速度快 40 倍。借助 TensorRT，您可以优化在所有主要框架中训练的神经网络模型，精确校正低精度，并最终将模型部署到超大规模数据中心、嵌入式或汽车产品平台中。



您可以从每个深度学习框架中将已训练模型导入到 TensorRT。



### NGC

NGC是什么？

https://docs.nvidia.com/ngc/index.html

NVIDIA GPU CLOUD 

gpu加速容器

包括catalog，registry。

It consists of containers, pre-trained models, Helm charts for Kubernetes deployments and industry specific AI toolkits with software development kits (SDKs)



The NGC private registry provides you with a secure space to store and share custom containers, models, resources, and helm charts within your enterprise.



NV 提供的helm-charts

GPU Operator：Deploy and Manage NVIDIA GPU resources in Kubernetes.

Triton Inference Server: TensorRT Inference Server Helm Chart







