## 20191114

[TOC]

### 手动安装k8s集群

https://github.com/opsnull/follow-me-install-kubernetes-cluster



#### 环境准备

Centos7

**系统初始化以及全局变量**

**主机名设置**

```
hostnamectl set-hostname k8s01
cat >> /etc/hosts <<EOF
192.168.159.148 k8s01
EOF
```

**安装依赖包**

```
yum install -y epel-release
yum install -y conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget

# epel-release  Extra Packages for Enterprise Linux装上了 EPEL之后，就相当于添加了一个第三方源
# ipvs 依赖 ipset
# ntp 保证各机器系统时间同步；
```

**禁用防火墙**

```
systemctl stop firewalld
systemctl disable firewalld
```

**禁用SELinux**

```
修改/etc/selinux/config文件内容，设置SELINUX=disabled
setenforce 0
getenfore
```

**关闭swap分区**

如果开启了swap分区，kubelet会启动失败（--fail-swap-on设置为false来忽略）

```
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

**设置系统时区**

```
# 调整系统 TimeZone
timedatectl set-timezone Asia/Shanghai
# 将当前的 UTC 时间写入硬件时钟
timedatectl set-local-rtc 0
# 重启依赖于系统时间的服务
systemctl restart rsyslog
systemctl restart crond
```

**加载内核模块**

```
modprobe ip_vs_rr
modprobe br_netfilter
```

**优化内核参数**

```
cat > kubernetes.conf <<EOF
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它
vm.overcommit_memory=1 # 不检查物理内存是否够用
vm.panic_on_oom=0 # 开启 OOM
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=1048576
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
EOF
cp kubernetes.conf /etc/sysctl.d/kubernetes.conf
sysctl -p /etc/sysctl.d/kubernetes.conf
```

注意：

net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1

net.netfilter.nf_conntrack_max=2310720  

这三个设置报错

sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: No such file or directory

sysctl: cannot stat /proc/sys/net/netfilter/nf_conntrack_max: No such file or directory

报错是因为没有加载ip_vs_rr，br_netfilter模块，即上一步没有做造成

**创建相关的目录**

```
mkdir -p /opt/k8s/{bin,work} /etc/{kubernetes,etcd}/cert

#这是一种创建多个目录的简写方式，不错
```

更新PATH变量

```
echo 'PATH=/opt/k8s/bin:$PATH' >>/root/.bashrc
source /root/.bashrc
```

#### 创建CA证书和秘钥

为确保安全，系统各组件使用x509证书对通信进行加密和认证。采用CloudFlare的PKI工具集cfssl创建所有证书

**安装cfssl工具集**

```
mkdir -p /opt/k8s/cert && cd /opt/k8s
wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
mv cfssl_linux-amd64 /opt/k8s/bin/cfssl
wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
mv cfssljson_linux-amd64 /opt/k8s/bin/cfssljson
wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64
mv cfssl-certinfo_linux-amd64 /opt/k8s/bin/cfssl-certinfo
chmod +x /opt/k8s/bin/*
export PATH=/opt/k8s/bin:$PATH
```

**创建根证书CA**

CA证书是集群所有节点共享，只需要创建一个证书，后续创建的证书都由它签名。



#### 下载安装包

获取k8s，etcd安装包



#### 服务配置

配置etcd服务

下载etcd二进制文件，将etcd和etcdctl文件拷贝到/usr/local/bin

生成/etc/etcd/etcd.conf配置文件

创建etcd service文件/usr/lib/systemd/system/etcd.service

systemctl daemon-reload
systemctl enable etcd.service --now
systemctl status etcd 



拷贝kube-apiserver，kube-scheduler， kube-controller-manager到/usr/local/bin

生成kube-apiserver的配置文件，创建服务，启动

生成kube-scheduler的配置文件，创建服务，启动

生成kube-controller-manager的配置文件，创建服务，启动



拷贝kubectl到/usr/local/bin



单机加入node节点

拷贝kube-proxy,kubelet到/usr/local/bin

同样分别创建配置文件和服务启动



开启clusterDNS

安装helm

安装prometheus

安装grafan



书上描述：

二进制文件介绍：

```
kube-apiserver: 
kube-controller-manager：
kube-scheduler:
kubectl:	//客户端命令行工具

kubelet:
kube-proxy:
kubeadm：   //集群安装命令行工具

暂时不用理会
apiextensions-apiserver  //自定义资源对象的扩展APIServer
cloud-controller-manager //云提供商服务对接的各种controller

```



Kubernetes的主要服务程序都可以通过直接运行二进制文件加上启动参数完成运行。

master上面需要部署etcd，kube-apiserver，kube-controller-manager，kube-scheduler服务进程。(Kubernetes集群的主数据库)

node上需要部署docker，kubelet，kube-proxy服务进程



1. 拷贝对应的二进制文件到对应的机器上面
2. 在/usr/lib/system/system目录下面为各服务创建systemd服务配置文件





KubeOperator











