## 20191118

[TOC]

kubespray

**kubeapps**

kubeapps是一个基于web的用户界面，用于部署和管理在kubernetes群集中的应用程序

### 安装kubeapps

```
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install --name kubeapps --namespace kubeapps  bitnami/kubeapps
Error: apprepositories.kubeapps.com "bitnami" already exists

卸载的时候还需要删除crd
helm delete --purge kubeapps
kubectl delete crd apprepositories.kubeapps.com
customresourcedefinition.apiextensions.k8s.io "apprepositories.kubeapps.com" deleted
kubectl delete secrets kubeapps-mongodb -n kubeapps
```

### Create API token

访问deshboard 需要k8s API token

```
kubectl create serviceaccount kubeapps-operator
kubectl create clusterrolebinding kubeapps-operator --clusterrole=cluster-admin --serviceaccount=default:kubeapps-operator
```

获取token

```
kubectl get secret $(kubectl get serviceaccount kubeapps-operator -o jsonpath='{range .secrets[*]}{.name}{"\n"}{end}' | grep kubeapps-operator-token) -o jsonpath='{.data.token}' -o go-template='{{.data.token | base64decode}}' && echo

eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6Imt1YmVhcHBzLW9wZXJhdG9yLXRva2VuLWt3ajd2Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6Imt1YmVhcHBzLW9wZXJhdG9yIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiODkwMjlhNTgtMGIzOC0xMWVhLTk1NGMtMDAwYzI5NWJhZmZjIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50OmRlZmF1bHQ6a3ViZWFwcHMtb3BlcmF0b3IifQ.uI00DZT38b_5QnF2VsB-PStF8USPQRg-7GA4MPmdrdC-kkfyIlvK8R7fTnw70lVjARm4ACO9Uju029umXeofwJAxSnRJv0--lWFfUQNLfL6Hz7r0FfPiM4CM8eFjPLPQudBgfsCGiDkPevbovSrf_eC0be06OdZ3-eCYDZVCDGecUacvNlsnQ7NMXkJ5FnLpdPBgXrgQVLBwXcqSa5Ng2QMTGj1Z7x_-QXoR-NIV12otK52YAv6hCWAj4bFjxuYV8ieRkdthT3TG6CD6XQG89Ukl4q4HThufyv4FWEPx8aB42sJ7YhmoS4Gl4BctUklWQQyf-_I5DvdGYfMw_ZZAsg
```

### 启动kubeapps dashboards

```
export POD_NAME=$(kubectl get pods -n kubeapps -l "app=kubeapps,release=kubeapps" -o jsonpath="{.items[0].metadata.name}")
echo "Visit http://127.0.0.1:9988 in your browser to access the Kubeapps Dashboard"
kubectl port-forward -n kubeapps $POD_NAME 9988:8080 --address 0.0.0.0
```

访问http://192.168.159.149:9988 输入上述token即可



碰到一个问题，首页闪一下然后就跳转到oauth2/sign-out页面了

把kubectl port-forward 放到后台运行就可以了。晕，不是的。



### 安装kubeOperator

```
# 查看防火墙状态
firewall-cmd --state
# 关闭防火墙
systemctl stop firewalld.service
# 获取压缩包
tar -zxvf kubeOperator-v2.1.58-release.tar.gz
cd kubeOperator-v2.1.58-release
# 运行安装脚本
./kubeopsctl.sh install
# 查看kubeOperator状态
systemctl status kubeops
```



安装解读

```
[root@localhost kubeOperator-v2.1.58-release]# ./kubeopsctl.sh install
>> Install docker
Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /etc/systemd/system/docker.service.
>> Install docker-compose
>>> 开始build镜像


调用 1_set_iptables.sh  {
//关闭防火墙
}

调用 2_install_docker.sh {
//安装docker（offline）、配置docker（/etc/docker/daemon.json）、启动docker(启动服务)、安装docker-compose

}

/usr/bin/docker-compose -f /opt/kubeoperator/docker-compose.yml up

```



请求/api/v1/setting/local_hostname/

请求/api/v1/credential/



### Harbor的安装

```
./install.sh --with-chartmuseum
```

停止harbor

```
docker-compose stop
```

修改nginx的配置

common/config/nginx/nginx.conf

启动harbor

```
docker-compose up -d
```



k8s的安装部署方式

* 完全手动部署，或者脚本集
* kubeAdm
* kubeSpray
* kubeasz
* rancher以及RKE
* kubeOperator
* kops



### 尝试RKE方式

1. 下载二进制安装包rke_linux-amd64 rke
2. 拷贝RKE二进制文件到/usr/local/bin路径下面，重命名为rke
3. 使RKE文件可执行
4. 准备kubernetes cluster nodes
5. 创建cluster配置文件**cluster.yml**
6. 在cluster.yml相同目录下面执行rke up



Manage Docker as a non-root user

```
useradd rancher
passwd rancher
groupadd docker
usermod -aG docker rancher
重启机器
```

```
# 配置免密码
# 在rke所在主机上创建秘钥
ssh-keygen

# 将所生成的密钥的公钥分发到各个节点
ssh-copy-id rancher@10.0.32.177
```

```
# cluster.yml
nodes:
    - address: 192.168.159.150
      user: rancher
      role:
        - controlplane
        - etcd
        - worker

```

```
[root@localhost rke-test]# rke up
INFO[0000] Running RKE version: v0.3.2                  
INFO[0000] Initiating Kubernetes cluster                
INFO[0000] [certificates] Generating admin certificates and kubeconfig 
INFO[0000] Successfully Deployed state file at [./cluster.rkestate] 
INFO[0000] Building Kubernetes cluster                  
INFO[0000] [dialer] Setup tunnel for host [192.168.159.150] 
INFO[0000] [network] Deploying port listener containers 
INFO[0000] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0000] Image [rancher/rke-tools:v0.1.50] does not exist on host [192.168.159.150]: Error: No such image: rancher/rke-tools:v0.1.50 
INFO[0000] Pulling image [rancher/rke-tools:v0.1.50] on host [192.168.159.150], try #1 
INFO[0056] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0056] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0056] Starting container [rke-etcd-port-listener] on host [192.168.159.150], try #1 
INFO[0056] [network] Successfully started [rke-etcd-port-listener] container on host [192.168.159.150] 
INFO[0056] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0056] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0057] Starting container [rke-cp-port-listener] on host [192.168.159.150], try #1 
INFO[0058] [network] Successfully started [rke-cp-port-listener] container on host [192.168.159.150] 
INFO[0058] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0058] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0058] Starting container [rke-worker-port-listener] on host [192.168.159.150], try #1 
INFO[0058] [network] Successfully started [rke-worker-port-listener] container on host [192.168.159.150] 
INFO[0058] [network] Port listener containers deployed successfully 
INFO[0058] [network] Running control plane -> etcd port checks 
INFO[0058] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0058] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0058] Starting container [rke-port-checker] on host [192.168.159.150], try #1 
INFO[0058] [network] Successfully started [rke-port-checker] container on host [192.168.159.150] 
INFO[0058] Removing container [rke-port-checker] on host [192.168.159.150], try #1 
INFO[0059] [network] Running control plane -> worker port checks 
INFO[0059] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0059] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0059] Starting container [rke-port-checker] on host [192.168.159.150], try #1 
INFO[0059] [network] Successfully started [rke-port-checker] container on host [192.168.159.150] 
INFO[0059] Removing container [rke-port-checker] on host [192.168.159.150], try #1 
INFO[0059] [network] Running workers -> control plane port checks 
INFO[0059] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0059] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0059] Starting container [rke-port-checker] on host [192.168.159.150], try #1 
INFO[0059] [network] Successfully started [rke-port-checker] container on host [192.168.159.150] 
INFO[0059] Removing container [rke-port-checker] on host [192.168.159.150], try #1 
INFO[0059] [network] Checking KubeAPI port Control Plane hosts 
INFO[0059] [network] Removing port listener containers  
INFO[0059] Removing container [rke-etcd-port-listener] on host [192.168.159.150], try #1 
INFO[0059] [remove/rke-etcd-port-listener] Successfully removed container on host [192.168.159.150] 
INFO[0059] Removing container [rke-cp-port-listener] on host [192.168.159.150], try #1 
INFO[0060] [remove/rke-cp-port-listener] Successfully removed container on host [192.168.159.150] 
INFO[0060] Removing container [rke-worker-port-listener] on host [192.168.159.150], try #1 
INFO[0060] [remove/rke-worker-port-listener] Successfully removed container on host [192.168.159.150] 
INFO[0060] [network] Port listener containers removed successfully 
INFO[0060] [certificates] Deploying kubernetes certificates to Cluster nodes 
INFO[0060] Checking if container [cert-deployer] is running on host [192.168.159.150], try #1 
INFO[0060] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0060] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0060] Starting container [cert-deployer] on host [192.168.159.150], try #1 
INFO[0060] Checking if container [cert-deployer] is running on host [192.168.159.150], try #1 
INFO[0065] Checking if container [cert-deployer] is running on host [192.168.159.150], try #1 
INFO[0065] Removing container [cert-deployer] on host [192.168.159.150], try #1 
INFO[0065] [reconcile] Rebuilding and updating local kube config 
INFO[0065] Successfully Deployed local admin kubeconfig at [./kube_config_cluster.yml] 
INFO[0065] [certificates] Successfully deployed kubernetes certificates to Cluster nodes 
INFO[0065] [reconcile] Reconciling cluster state        
INFO[0065] [reconcile] This is newly generated cluster  
INFO[0065] Pre-pulling kubernetes images                
INFO[0065] Checking if image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150], try #1 
INFO[0065] Image [rancher/hyperkube:v1.15.5-rancher1] does not exist on host [192.168.159.150]: Error: No such image: rancher/hyperkube:v1.15.5-rancher1 
INFO[0065] Pulling image [rancher/hyperkube:v1.15.5-rancher1] on host [192.168.159.150], try #1 
INFO[0402] Checking if image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150], try #1 
INFO[0402] Image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150] 
INFO[0402] Kubernetes images pulled successfully        
INFO[0402] [etcd] Building up etcd plane..              
INFO[0402] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0402] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0403] Starting container [etcd-fix-perm] on host [192.168.159.150], try #1 
INFO[0404] Successfully started [etcd-fix-perm] container on host [192.168.159.150] 
INFO[0404] Waiting for [etcd-fix-perm] container to exit on host [192.168.159.150] 
INFO[0404] Waiting for [etcd-fix-perm] container to exit on host [192.168.159.150] 
INFO[0404] Container [etcd-fix-perm] is still running on host [192.168.159.150] 
INFO[0405] Waiting for [etcd-fix-perm] container to exit on host [192.168.159.150] 
INFO[0405] Checking if image [rancher/coreos-etcd:v3.3.10-rancher1] exists on host [192.168.159.150], try #1 
INFO[0405] Image [rancher/coreos-etcd:v3.3.10-rancher1] does not exist on host [192.168.159.150]: Error: No such image: rancher/coreos-etcd:v3.3.10-rancher1 
INFO[0405] Pulling image [rancher/coreos-etcd:v3.3.10-rancher1] on host [192.168.159.150], try #1 
INFO[0431] Checking if image [rancher/coreos-etcd:v3.3.10-rancher1] exists on host [192.168.159.150], try #1 
INFO[0431] Image [rancher/coreos-etcd:v3.3.10-rancher1] exists on host [192.168.159.150] 
INFO[0431] Starting container [etcd] on host [192.168.159.150], try #1 
INFO[0431] [etcd] Successfully started [etcd] container on host [192.168.159.150] 
INFO[0431] [etcd] Running rolling snapshot container [etcd-snapshot-once] on host [192.168.159.150] 
INFO[0431] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0431] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0431] Starting container [etcd-rolling-snapshots] on host [192.168.159.150], try #1 
INFO[0431] [etcd] Successfully started [etcd-rolling-snapshots] container on host [192.168.159.150] 
INFO[0436] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0436] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0436] Starting container [rke-bundle-cert] on host [192.168.159.150], try #1 
INFO[0438] [certificates] Successfully started [rke-bundle-cert] container on host [192.168.159.150] 
INFO[0438] Waiting for [rke-bundle-cert] container to exit on host [192.168.159.150] 
INFO[0438] Container [rke-bundle-cert] is still running on host [192.168.159.150] 
INFO[0439] Waiting for [rke-bundle-cert] container to exit on host [192.168.159.150] 
INFO[0439] [certificates] successfully saved certificate bundle [/opt/rke/etcd-snapshots//pki.bundle.tar.gz] on host [192.168.159.150] 
INFO[0439] Removing container [rke-bundle-cert] on host [192.168.159.150], try #1 
INFO[0439] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0439] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0439] Starting container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0440] [etcd] Successfully started [rke-log-linker] container on host [192.168.159.150] 
INFO[0440] Removing container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0440] [remove/rke-log-linker] Successfully removed container on host [192.168.159.150] 
INFO[0440] [etcd] Successfully started etcd plane.. Checking etcd cluster health 
INFO[0440] [controlplane] Building up Controller Plane.. 
INFO[0440] Checking if container [service-sidekick] is running on host [192.168.159.150], try #1 
INFO[0440] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0440] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0440] Checking if image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150], try #1 
INFO[0441] Image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150] 
INFO[0441] Starting container [kube-apiserver] on host [192.168.159.150], try #1 
INFO[0441] [controlplane] Successfully started [kube-apiserver] container on host [192.168.159.150] 
INFO[0441] [healthcheck] Start Healthcheck on service [kube-apiserver] on host [192.168.159.150] 
INFO[0453] [healthcheck] service [kube-apiserver] on host [192.168.159.150] is healthy 
INFO[0453] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0453] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0453] Starting container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0453] [controlplane] Successfully started [rke-log-linker] container on host [192.168.159.150] 
INFO[0453] Removing container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0453] [remove/rke-log-linker] Successfully removed container on host [192.168.159.150] 
INFO[0453] Checking if image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150], try #1 
INFO[0453] Image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150] 
INFO[0453] Starting container [kube-controller-manager] on host [192.168.159.150], try #1 
INFO[0454] [controlplane] Successfully started [kube-controller-manager] container on host [192.168.159.150] 
INFO[0454] [healthcheck] Start Healthcheck on service [kube-controller-manager] on host [192.168.159.150] 
INFO[0459] [healthcheck] service [kube-controller-manager] on host [192.168.159.150] is healthy 
INFO[0459] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0459] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0459] Starting container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0460] [controlplane] Successfully started [rke-log-linker] container on host [192.168.159.150] 
INFO[0460] Removing container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0460] [remove/rke-log-linker] Successfully removed container on host [192.168.159.150] 
INFO[0460] Checking if image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150], try #1 
INFO[0460] Image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150] 
INFO[0460] Starting container [kube-scheduler] on host [192.168.159.150], try #1 
INFO[0460] [controlplane] Successfully started [kube-scheduler] container on host [192.168.159.150] 
INFO[0460] [healthcheck] Start Healthcheck on service [kube-scheduler] on host [192.168.159.150] 
INFO[0466] [healthcheck] service [kube-scheduler] on host [192.168.159.150] is healthy 
INFO[0466] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0466] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0466] Starting container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0466] [controlplane] Successfully started [rke-log-linker] container on host [192.168.159.150] 
INFO[0466] Removing container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0466] [remove/rke-log-linker] Successfully removed container on host [192.168.159.150] 
INFO[0466] [controlplane] Successfully started Controller Plane.. 
INFO[0466] [authz] Creating rke-job-deployer ServiceAccount 
INFO[0467] [authz] rke-job-deployer ServiceAccount created successfully 
INFO[0467] [authz] Creating system:node ClusterRoleBinding 
INFO[0467] [authz] system:node ClusterRoleBinding created successfully 
INFO[0467] [authz] Creating kube-apiserver proxy ClusterRole and ClusterRoleBinding 
INFO[0467] [authz] kube-apiserver proxy ClusterRole and ClusterRoleBinding created successfully 
INFO[0467] Successfully Deployed state file at [./cluster.rkestate] 
INFO[0467] [state] Saving full cluster state to Kubernetes 
INFO[0467] [state] Successfully Saved full cluster state to Kubernetes ConfigMap: cluster-state 
INFO[0467] [worker] Building up Worker Plane..          
INFO[0467] Checking if container [service-sidekick] is running on host [192.168.159.150], try #1 
INFO[0467] [sidekick] Sidekick container already created on host [192.168.159.150] 
INFO[0467] Checking if image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150], try #1 
INFO[0467] Image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150] 
INFO[0467] Starting container [kubelet] on host [192.168.159.150], try #1 
INFO[0467] [worker] Successfully started [kubelet] container on host [192.168.159.150] 
INFO[0467] [healthcheck] Start Healthcheck on service [kubelet] on host [192.168.159.150] 
INFO[0473] [healthcheck] service [kubelet] on host [192.168.159.150] is healthy 
INFO[0473] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0473] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0473] Starting container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0473] [worker] Successfully started [rke-log-linker] container on host [192.168.159.150] 
INFO[0473] Removing container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0474] [remove/rke-log-linker] Successfully removed container on host [192.168.159.150] 
INFO[0474] Checking if image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150], try #1 
INFO[0474] Image [rancher/hyperkube:v1.15.5-rancher1] exists on host [192.168.159.150] 
INFO[0474] Starting container [kube-proxy] on host [192.168.159.150], try #1 
INFO[0474] [worker] Successfully started [kube-proxy] container on host [192.168.159.150] 
INFO[0474] [healthcheck] Start Healthcheck on service [kube-proxy] on host [192.168.159.150] 
INFO[0479] [healthcheck] service [kube-proxy] on host [192.168.159.150] is healthy 
INFO[0479] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0479] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0480] Starting container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0480] [worker] Successfully started [rke-log-linker] container on host [192.168.159.150] 
INFO[0480] Removing container [rke-log-linker] on host [192.168.159.150], try #1 
INFO[0480] [remove/rke-log-linker] Successfully removed container on host [192.168.159.150] 
INFO[0480] [worker] Successfully started Worker Plane.. 
INFO[0480] Checking if image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150], try #1 
INFO[0480] Image [rancher/rke-tools:v0.1.50] exists on host [192.168.159.150] 
INFO[0480] Starting container [rke-log-cleaner] on host [192.168.159.150], try #1 
INFO[0480] [cleanup] Successfully started [rke-log-cleaner] container on host [192.168.159.150] 
INFO[0480] Removing container [rke-log-cleaner] on host [192.168.159.150], try #1 
INFO[0480] [remove/rke-log-cleaner] Successfully removed container on host [192.168.159.150] 
INFO[0480] [sync] Syncing nodes Labels and Taints       
INFO[0480] [sync] Successfully synced nodes Labels and Taints 
INFO[0480] [network] Setting up network plugin: canal   
INFO[0480] [addons] Saving ConfigMap for addon rke-network-plugin to Kubernetes 
INFO[0480] [addons] Successfully saved ConfigMap for addon rke-network-plugin to Kubernetes 
INFO[0480] [addons] Executing deploy job rke-network-plugin 
INFO[0495] [addons] Setting up coredns                  
INFO[0495] [addons] Saving ConfigMap for addon rke-coredns-addon to Kubernetes 
INFO[0495] [addons] Successfully saved ConfigMap for addon rke-coredns-addon to Kubernetes 
INFO[0495] [addons] Executing deploy job rke-coredns-addon 
INFO[0506] [addons] CoreDNS deployed successfully..     
INFO[0506] [dns] DNS provider coredns deployed successfully 
INFO[0506] [addons] Setting up Metrics Server           
INFO[0506] [addons] Saving ConfigMap for addon rke-metrics-addon to Kubernetes 
INFO[0506] [addons] Successfully saved ConfigMap for addon rke-metrics-addon to Kubernetes 
INFO[0506] [addons] Executing deploy job rke-metrics-addon 
INFO[0511] [addons] Metrics Server deployed successfully 
INFO[0511] [ingress] Setting up nginx ingress controller 
INFO[0511] [addons] Saving ConfigMap for addon rke-ingress-controller to Kubernetes 
INFO[0511] [addons] Successfully saved ConfigMap for addon rke-ingress-controller to Kubernetes 
INFO[0511] [addons] Executing deploy job rke-ingress-controller 
INFO[0516] [ingress] ingress controller nginx deployed successfully 
INFO[0516] [addons] Setting up user addons              
INFO[0516] [addons] no user addons defined              
INFO[0516] Finished building Kubernetes cluster successfully
```

```
# 下载安装kubectl客户端
curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.16.0/bin/linux/amd64/kubectl

chmod +x kubectl

./kubectl --kubeconfig kube_config_cluster.yml version
Client Version: version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.3", GitCommit:"b3cbbae08ec52a7fc73d334838e18d17e8512749", GitTreeState:"clean", BuildDate:"2019-11-13T11:23:11Z", GoVersion:"go1.12.12", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"15", GitVersion:"v1.15.5", GitCommit:"20c265fef0741dd71a66480e35bd69f18351daea", GitTreeState:"clean", BuildDate:"2019-10-15T19:07:57Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"}
```



