## 离线安装Rancher参考

[TOC]

### 前言

Rancher是一套容器管理平台，使用它可以轻松的管理各种环境的Kubernetes，并可以在生产环境中快速的部署和管理容器。下文参照Rancher官网，对离线部署Rancher进行了实践。

*所需文件，归档至\\\10.3.2.11\dti\FileServer\LuCheng_WH\rancher目录*

### 准备

1. 下载镜像上传到私有仓库

   * 从Rancher github的发布页面获取对应版本的rancher-images.txt文件
   * 复制以下脚本保存为rancher-save-images.sh

   ```shell
   #!/bin/bash
   # 定义日志
   workdir=`pwd`
   log_file=${workdir}/sync_images_$(date +"%Y-%m-%d").log
   
   logger()
   {
       log=$1
       cur_time='['$(date +"%Y-%m-%d %H:%M:%S")']'
       echo ${cur_time} ${log} | tee -a ${log_file}
   }
   
   list="rancher-images.txt"
   #images="rancher-images.tar.gz"
   
   POSITIONAL=()
   while [[ $# -gt 0 ]]; do
       key="$1"
       case $key in
           -i|--images)
           images="$2"
           shift # past argument
           shift # past value
           ;;
           -l|--image-list)
           list="$2"
           shift # past argument
           shift # past value
           ;;
           -h|--help)
           help="true"
           shift
       ;;
       esac
   done
   
   usage () {
       echo "USAGE: $0 [--image-list rancher-images.txt] [--images rancher-images.tar.gz]"
       echo "  [-l|--images-list path] text file with list of images. 1 per line."
       echo "  [-l|--images path] tar.gz generated by docker save."
       echo "  [-h|--help] Usage message"
   }
   
   if [[ $help ]]; then
       usage
       exit 0
   fi
   
   mkdir -p rancher-images-$(date +"%Y-%m-%d")
   
   for i in $(cat ${list});
   do
       if [[ ! -f rancher-images-$(date +"%Y-%m-%d")/$(echo $i | sed "s#/#-#g; s#:#-#g").tgz ]];then
   
           docker pull ${i}
   
           if [ $? -ne 0 ]; then
               logger "${i} pull failed."
           else
               logger "${i} pull successfully."
           fi
   
           docker save ${i} | gzip > rancher-images-$(date +"%Y-%m-%d")/$(echo $i | sed "s#/#-#g; s#:#-#g").tgz
   
           if [ $? -ne 0 ]; then
               logger "${i} save failed."
           else
               logger "${i} save successfully."
           fi
   
       else
           logger "${i} Images downloaded."
       fi
   done
   ```

   * 复制以下内容保存为rancher-push-images.sh

   ```shell
   #!/bin/bash
   
   ## 镜像上传说明
   # 需要先在镜像仓库中创建 rancher 项目
   # 根据实际情况更改以下私有仓库地址
   
   # 定义日志
   workdir=`pwd`
   log_file=${workdir}/sync_images_$(date +"%Y-%m-%d").log
   
   logger()
   {
       log=$1
       cur_time='['$(date +"%Y-%m-%d %H:%M:%S")']'
       echo ${cur_time} ${log} | tee -a ${log_file}
   }
   
   images_hub() {
   
       while true; do
           read -p "输入镜像仓库地址(不加http/https): " registry
           read -p "输入镜像仓库用户名: " registry_user
           read -p "输入镜像仓库用户密码: " registry_password
           echo "您设置的仓库地址为: ${registry},用户名: ${registry_user},密码: xxx"
           read -p "是否确认(Y/N): " confirm
   
           if [ $confirm != Y ] && [ $confirm != y ] && [ $confirm == '' ]; then
               echo "输入不能为空，重新输入"
           else
               break
           fi
       done
   }
   
   images_hub
   
   echo "镜像仓库 $(docker login -u ${registry_user} -p ${registry_password} ${registry})"
   
   #images=$(docker images -a | grep -v TAG | awk '{print $1 ":" $2}')
   
   images=$(cat rancher-images.txt )
   
   # 定义全局项目，如果想把镜像全部同步到一个仓库，则指定一个全局项目名称；
   global_namespace=   # rancher
   
   docker_push() {
       for imgs in $(echo ${images}); do
           if [[ -n "$global_namespace" ]]; then
   
               n=$(echo ${imgs} | awk -F"/" '{print NF-1}')
               # 如果镜像名中没有/，那么此镜像一定是library仓库的镜像；
               if [ ${n} -eq 0 ]; then
                   img_tag=${imgs}
   
                   #重命名镜像
                   docker tag ${imgs} ${registry}/${global_namespace}/${img_tag}
   
                   #删除原始镜像
                   #docker rmi ${imgs}
                   #上传镜像
                   docker push ${registry}/${global_namespace}/${img_tag}
   
               # 如果镜像名中有一个/，那么/左侧为项目名，右侧为镜像名和tag
               elif [ ${n} -eq 1 ]; then
                   img_tag=$(echo ${imgs} | awk -F"/" '{print $2}')
   
                   #重命名镜像
                   docker tag ${imgs} ${registry}/${global_namespace}/${img_tag}
                   #删除旧镜像
                   #docker rmi ${imgs}
                   #上传镜像
                   docker push ${registry}/${global_namespace}/${img_tag}
   
               # 如果镜像名中有两个/，
               elif [ ${n} -eq 2 ]; then
                   img_tag=$(echo ${imgs} | awk -F"/" '{print $3}')
   
                   #重命名镜像
                   docker tag ${imgs} ${registry}/${global_namespace}/${img_tag}
                   #删除旧镜像
                   #docker rmi ${imgs}
                   #上传镜像
                   docker push ${registry}/${global_namespace}/${img_tag}
               else
                   #标准镜像为四层结构，即：仓库地址/项目名/镜像名:tag,如不符合此标准，即为非有效镜像。
                   echo "No available images"
               fi
           else
   
               n=$(echo ${imgs} | awk -F"/" '{print NF-1}')
               # 如果镜像名中没有/，那么此镜像一定是library仓库的镜像；
               if [ ${n} -eq 0 ]; then
                   img_tag=${imgs}
                   namespace=library
                   #重命名镜像
                   docker tag ${imgs} ${registry}/${namespace}/${img_tag}
                   #删除原始镜像
                   #docker rmi ${imgs}
                   #上传镜像
                   docker push ${registry}/${namespace}/${img_tag}
   
               # 如果镜像名中有一个/，那么/左侧为项目名，右侧为镜像名和tag
               elif [ ${n} -eq 1 ]; then
                   img_tag=$(echo ${imgs} | awk -F"/" '{print $2}')
                   namespace=$(echo ${imgs} | awk -F"/" '{print $1}')
   
                   #重命名镜像
                   docker tag ${imgs} ${registry}/${namespace}/${img_tag}
                   #删除旧镜像
                   #docker rmi ${imgs}
                   #上传镜像
                   docker push ${registry}/${namespace}/${img_tag}
   
               # 如果镜像名中有两个/，
               elif [ ${n} -eq 2 ]; then
                   img_tag=$(echo ${imgs} | awk -F"/" '{print $3}')
                   namespace=$(echo ${imgs} | awk -F"/" '{print $2}')
   
                   #重命名镜像
                   docker tag ${imgs} ${registry}/${namespace}/${img_tag}
                   #删除旧镜像
                   #docker rmi ${imgs}
                   #上传镜像
                   docker push ${registry}/${namespace}/${img_tag}
               else
                   #标准镜像为四层结构，即：仓库地址/项目名/镜像名:tag,如不符合此标准，即为非有效镜像。
                   echo "No available images"
               fi
   
           fi
       done
   }
   
   docker_push
   ```

   * 将上述三个文件上传到一台在可访问internet的主机中，执行如下命令

   ```shell
   # 执行rancher-save-images.sh脚本，结果会在目录rancher-images-$(date +"%Y-%m-%d")中生成所有镜像的压缩文件
   chmod +x ./rancher-save-images.sh
   ./rancher-save-images.sh --image-list ./rancher-images.txt
   
   # 执行rancher-push-images.sh脚本，输入私有仓库的地址（这里使用174 Harbor仓库）
   chmod +x ./rancher-push-images.sh
   ./rancher-push-images.sh
   输入镜像仓库地址(不加http/https): registry.uih
   输入镜像仓库用户名: admin
   输入镜像仓库用户密码: xxxxx
   ```

2. 机器以及软件准备

   准备四台机器

   - rancher-client：10.6.209.11
   - rancher-node1：10.6.209.26
   - rancher-node2：10.6.209.27
   - rancher-node3：10.6.209.28

   准备相应的软件

   * kubectl：Kubernetes命令行工具
   * rke：Rancher Kubernetes Engine，用于构建Kubernetes集群的cli
   * helm：Kubernetes的包管理

### RKE安装k8s

1. 安装docker

```shell
# root 分别登录rancher-node1，rancher-node2，rancher-node3 执行如下命令
rpm -qa container-selinux-2.107-3.el7.noarch.rpm
rpm -qa containerd.io-1.2.10-3.2.el7.x86_64.rpm
rpm -qa docker-ce-cli-19.03.4-3.el7.x86_64.rpm
rpm -qa containerd.io-1.2.10-3.2.el7.x86_64.rpm

# 配置使用私有仓库
vi /etc/docker/daemon.json 
{
    "registry-mirrors": ["http://f1361db2.m.daocloud.io"],
    "insecure-registries":["registry.uih"]
}
service docker reload

# 基于安全考虑，创建非root用户管理Docker
useradd rancher
passwd rancher
groupadd docker
usermod -aG docker rancher

```

2. 配置ssh免密码登录

```shell
# 在rancher-client所在主机上创建秘钥
ssh-keygen

# 将所生成的密钥的公钥分发到各个节点
ssh-copy-id rancher@10.6.209.26
ssh-copy-id rancher@10.6.209.27
ssh-copy-id rancher@10.6.209.28

# 如果直接执行下面命令登录成功，不需要输入秘密，即配置成功
ssh rancher@10.6.209.26
ssh rancher@10.6.209.27
ssh rancher@10.6.209.28
```

3. 创建RKE配置文件

```yaml
# 在rancher-client所在主机上面创建包含如下内容文件cluster.yml
nodes:
- address: 10.6.209.26            # node air gap network IP
  user: rancher
  role: [ "controlplane", "etcd", "worker" ]
- address: 10.6.209.27            # node air gap network IP
  user: rancher
  role: [ "controlplane", "etcd", "worker" ]
- address: 10.6.209.28            # node air gap network IP
  user: rancher
  role: [ "controlplane", "etcd", "worker" ]

private_registries:
- url: registry.uih # private registry url
  user: admin
  password: "xxxxxxx"
  is_default: true

services:
  etcd:
    extra_args:
      auto-compaction-retention: 240 #(单位小时)
      # 修改空间配额为$((6*1024*1024*1024))，默认2G,最大8G
      quota-backend-bytes: '6442450944'
    backup_config:
      enabled: false       # 设置true启用ETCD自动备份，设置false禁用；
      interval_hours: 12  # 快照创建间隔时间，不加此参数，默认5分钟；
      retention: 6        # etcd备份保留份数；
      ### S3配置选项
      s3backupconfig:
        access_key: "myaccesskey"
        secret_key:  "myaccesssecret"
        bucket_name: "my-backup-bucket"
        folder: "folder-name" # 此参数v2.3.0之后可用
        endpoint: "s3.eu-west-1.amazonaws.com"
        region: "eu-west-1"

```

4. 创建kubernetes集群

```shell
# 安装 rke_linux-amd64
chmod +x rke_linux-amd64
mv rke_linux-amd64 /usr/bin/rke

# 在cluster.yml同级目录下面执行如下命令
rke up
INFO[0000] Running RKE version: v1.0.4                  
INFO[0000] Initiating Kubernetes cluster                
INFO[0000] [certificates] Generating admin certificates and kubeconfig 
INFO[0000] Successfully Deployed state file at [./cluster.rkestate] 
INFO[0000] Building Kubernetes cluster                  
INFO[0000] [dialer] Setup tunnel for host [10.6.209.28] 
INFO[0000] [dialer] Setup tunnel for host [10.6.209.27] 
INFO[0000] [dialer] Setup tunnel for host [10.6.209.26]
......

# 提示成功后，会在当前目录下面生成kube_config_cluster.yml文件
```

5. 测试集群

```shell
# 拷贝上一步骤生成的kube_config_cluster.yml到rancher-node1
# 拷贝kubctl文件到rancher-node1,并安装
chmod +x kubectl 
mv kubectl /usr/bin/

mkdir .kube
mv kube_config_cluster.yml .kube/config

# 查看节点信息
kubectl get nodes
NAME          STATUS   ROLES                      AGE    VERSION
10.6.209.26   Ready    controlplane,etcd,worker   3d1h   v1.17.2
10.6.209.27   Ready    controlplane,etcd,worker   3d1h   v1.17.2
10.6.209.28   Ready    controlplane,etcd,worker   3d1h   v1.17.2

# 检查pod运行状态
kubectl get pods --all-namespaces
ingress-nginx               default-http-backend-8bc95c5b8-f28gp                       1/1     Running            0          3d1h
ingress-nginx               nginx-ingress-controller-9frfz                             1/1     Running            0          3d1h
ingress-nginx               nginx-ingress-controller-tdp8q                             1/1     Running            0          3d1h
ingress-nginx               nginx-ingress-controller-zrntn                             1/1     Running            0          3d1h
kube-system                 canal-5q2bs                                                2/2     Running            0          3d1h
kube-system                 canal-plmt2                                                2/2     Running            0          3d1h
kube-system                 canal-s26p6                                                2/2     Running            0          3d1h
kube-system                 coredns-864b56d768-4t9d8                                   1/1     Running            0          3d1h
kube-system                 coredns-864b56d768-ktpr5                                   1/1     Running            0          3d1h
kube-system                 coredns-autoscaler-566d495c56-48spl                        1/1     Running            0          3d1h
kube-system                 metrics-server-5f7dfc7fd4-jjb6t                            1/1     Running            0          3d1h
kube-system                 rke-coredns-addon-deploy-job-rj8tw                         0/1     Completed          0          3d1h
kube-system                 rke-ingress-controller-deploy-job-p7vwt                    0/1     Completed          0          3d1h
kube-system                 rke-metrics-addon-deploy-job-ddswf                         0/1     Completed          0          3d1h
kube-system                 rke-network-plugin-deploy-job-dppwm                        0/1     Completed          0          3d1h

```

### 安装Rancher

1. 安装Helm，并初始化helm

```shell
# 在rancher-node1安装helm客户端
tar -zxvf helm-v2.16.1-linux-amd64.tar.gz
cp ./linux-amd64/helm /usr/bin/

# 安装helm服务端tiller
kubectl -n kube-system create serviceaccount tiller

kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller

helm init --skip-refresh --service-account tiller --tiller-image registry.uih/rancher/tiller:v2.15.2

# 检查安装是否成功
helm version
Client: &version.Version{SemVer:"v2.15.2", GitCommit:"8dce272473e5f2a7bf58ce79bb5c3691db54c96b", GitTreeState:"clean"}
Server: &version.Version{SemVer:"v2.15.2", GitCommit:"8dce272473e5f2a7bf58ce79bb5c3691db54c96b", GitTreeState:"clean"}

```

2. 获取charts模板，并安装

```shell
# 获取server-chart.zip文件并解压

# 创建自签名证书
./create_self-signed-cert.sh 
--ssl-trusted-ip=10.6.209.26,10.6.209.27,10.6.209.28 --ssl-size=2048 --ssl-date=3650

# 配置ssl证书
kubectl create namespace cattle-system

# 创建ssl证书密文
kubectl -n cattle-system create secret tls tls-rancher-ingress --cert=./tls.crt --key=./tls.key

# 创建CA证书密文
kubectl -n cattle-system create secret generic tls-ca --from-file=cacerts.pem

# helm 安装Rancher
helm install 
  --name rancher \
  --namespace cattle-system \
  --set rancherImage=registry.uih/rancher/rancher \
  --set busyboxImage=registry.uih/rancher/busybox \
  --set service.type=NodePort \
  --set service.ports.nodePort=30303  \
  --set privateCA=true \
  --set useBundledSystemChart=true \
  server-chart/rancher
```

3. 查看rancher的运行状态，并访问

```shell
kubectl get pods -n cattle-system
cattle-system               rancher-85b6f9c957-747bh                                   2/2     Running            2          3d1h
cattle-system               rancher-85b6f9c957-sprmd                                   2/2     Running            2          3d1h
cattle-system               rancher-85b6f9c957-w2jxj                                   2/2     Running            2          3d1h
```

访问https://10.6.209.26:30303，提示输入admin密码，并设置server_url， 稍等片刻可以看到local集群状态变成Active。

![img](C:\Users\cheng.lu\AppData\Local\Temp\企业微信截图_15819324266748.png)

